{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address Extraction, Address Parsing and Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import codecs, json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from address_parser import Parser\n",
    "import usaddress\n",
    "from postal.parser import parse_address\n",
    "from postal.expand import expand_address\n",
    "\n",
    "import censusdata\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "from geocodio import GeocodioClient\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Combined NTU & Kaggle Tweet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./data/df_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267682, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>8.96827e+17</td>\n",
       "      <td>Gert could become a quite intense post-tropica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97013e+17</td>\n",
       "      <td>Weather Street: Tropical Storm Harvey, Hurrica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97087e+17</td>\n",
       "      <td>Tropical Storm #Gert intensifying. Tropical St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97088e+17</td>\n",
       "      <td>Tropical Storm #Gert intensifying. Tropical St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97088e+17</td>\n",
       "      <td>RT YourNews15 \"Tropical Storm #Gert intensifyi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           id                                              tweet\n",
       "0  2017-08-13  8.96827e+17  Gert could become a quite intense post-tropica...\n",
       "1  2017-08-14  8.97013e+17  Weather Street: Tropical Storm Harvey, Hurrica...\n",
       "2  2017-08-14  8.97087e+17  Tropical Storm #Gert intensifying. Tropical St...\n",
       "3  2017-08-14  8.97088e+17  Tropical Storm #Gert intensifying. Tropical St...\n",
       "4  2017-08-14  8.97088e+17  RT YourNews15 \"Tropical Storm #Gert intensifyi..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Labeled Data CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Nb'label' is CSV from Naive Bayes classification model in previous notebook\n",
    "\n",
    "df_nb = pd.read_csv('./data/nb_labels.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Tweet dataframe and labels dataframe\n",
    "\n",
    "df = pd.concat([df_1, df_nb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nb_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>8.96827e+17</td>\n",
       "      <td>Gert could become a quite intense post-tropica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97013e+17</td>\n",
       "      <td>Weather Street: Tropical Storm Harvey, Hurrica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97087e+17</td>\n",
       "      <td>Tropical Storm #Gert intensifying. Tropical St...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97088e+17</td>\n",
       "      <td>Tropical Storm #Gert intensifying. Tropical St...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>8.97088e+17</td>\n",
       "      <td>RT YourNews15 \"Tropical Storm #Gert intensifyi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           id                                              tweet  \\\n",
       "0  2017-08-13  8.96827e+17  Gert could become a quite intense post-tropica...   \n",
       "1  2017-08-14  8.97013e+17  Weather Street: Tropical Storm Harvey, Hurrica...   \n",
       "2  2017-08-14  8.97087e+17  Tropical Storm #Gert intensifying. Tropical St...   \n",
       "3  2017-08-14  8.97088e+17  Tropical Storm #Gert intensifying. Tropical St...   \n",
       "4  2017-08-14  8.97088e+17  RT YourNews15 \"Tropical Storm #Gert intensifyi...   \n",
       "\n",
       "   nb_label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    266677\n",
       "1      1005\n",
       "Name: nb_label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Emergency labeled value counts\n",
    "\n",
    "df['nb_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Filtered Dataframe for only Emergency Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_help = df[df['nb_label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_help.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Texas Cities Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texas cities from US CensusData Population Estimates\n",
    "\n",
    "tx_cities = pd.read_csv('./data/geodb/texas_cities.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Id2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>April 1, 2010 - Census</th>\n",
       "      <th>April 1, 2010 - Estimates Base</th>\n",
       "      <th>Population Estimate (as of July 1) - 2010</th>\n",
       "      <th>Population Estimate (as of July 1) - 2011</th>\n",
       "      <th>Population Estimate (as of July 1) - 2012</th>\n",
       "      <th>Population Estimate (as of July 1) - 2013</th>\n",
       "      <th>Population Estimate (as of July 1) - 2014</th>\n",
       "      <th>Population Estimate (as of July 1) - 2015</th>\n",
       "      <th>Population Estimate (as of July 1) - 2016</th>\n",
       "      <th>Population Estimate (as of July 1) - 2017</th>\n",
       "      <th>Population Estimate (as of July 1) - 2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1620000US4800100</td>\n",
       "      <td>4800100</td>\n",
       "      <td>Abbott city, Texas</td>\n",
       "      <td>356</td>\n",
       "      <td>361</td>\n",
       "      <td>362</td>\n",
       "      <td>362</td>\n",
       "      <td>361</td>\n",
       "      <td>358</td>\n",
       "      <td>354</td>\n",
       "      <td>354</td>\n",
       "      <td>357</td>\n",
       "      <td>363</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1620000US4800160</td>\n",
       "      <td>4800160</td>\n",
       "      <td>Abernathy city, Texas</td>\n",
       "      <td>2805</td>\n",
       "      <td>2812</td>\n",
       "      <td>2818</td>\n",
       "      <td>2833</td>\n",
       "      <td>2822</td>\n",
       "      <td>2796</td>\n",
       "      <td>2743</td>\n",
       "      <td>2725</td>\n",
       "      <td>2747</td>\n",
       "      <td>2745</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1620000US4801000</td>\n",
       "      <td>4801000</td>\n",
       "      <td>Abilene city, Texas</td>\n",
       "      <td>117063</td>\n",
       "      <td>117512</td>\n",
       "      <td>117806</td>\n",
       "      <td>118749</td>\n",
       "      <td>119852</td>\n",
       "      <td>119792</td>\n",
       "      <td>120647</td>\n",
       "      <td>121694</td>\n",
       "      <td>121856</td>\n",
       "      <td>122210</td>\n",
       "      <td>122999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1620000US4801108</td>\n",
       "      <td>4801108</td>\n",
       "      <td>Ackerly city, Texas</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>225</td>\n",
       "      <td>228</td>\n",
       "      <td>230</td>\n",
       "      <td>231</td>\n",
       "      <td>226</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1620000US4801240</td>\n",
       "      <td>4801240</td>\n",
       "      <td>Addison town, Texas</td>\n",
       "      <td>13056</td>\n",
       "      <td>13062</td>\n",
       "      <td>13091</td>\n",
       "      <td>13798</td>\n",
       "      <td>15199</td>\n",
       "      <td>15437</td>\n",
       "      <td>15501</td>\n",
       "      <td>15587</td>\n",
       "      <td>15516</td>\n",
       "      <td>15497</td>\n",
       "      <td>15945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id      Id2              Geography April 1, 2010 - Census  \\\n",
       "0  1620000US4800100  4800100     Abbott city, Texas                    356   \n",
       "1  1620000US4800160  4800160  Abernathy city, Texas                   2805   \n",
       "2  1620000US4801000  4801000    Abilene city, Texas                 117063   \n",
       "3  1620000US4801108  4801108    Ackerly city, Texas                    220   \n",
       "4  1620000US4801240  4801240    Addison town, Texas                  13056   \n",
       "\n",
       "   April 1, 2010 - Estimates Base  Population Estimate (as of July 1) - 2010  \\\n",
       "0                             361                                        362   \n",
       "1                            2812                                       2818   \n",
       "2                          117512                                     117806   \n",
       "3                             220                                        220   \n",
       "4                           13062                                      13091   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2011  \\\n",
       "0                                        362   \n",
       "1                                       2833   \n",
       "2                                     118749   \n",
       "3                                        219   \n",
       "4                                      13798   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2012  \\\n",
       "0                                        361   \n",
       "1                                       2822   \n",
       "2                                     119852   \n",
       "3                                        219   \n",
       "4                                      15199   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2013  \\\n",
       "0                                        358   \n",
       "1                                       2796   \n",
       "2                                     119792   \n",
       "3                                        225   \n",
       "4                                      15437   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2014  \\\n",
       "0                                        354   \n",
       "1                                       2743   \n",
       "2                                     120647   \n",
       "3                                        228   \n",
       "4                                      15501   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2015  \\\n",
       "0                                        354   \n",
       "1                                       2725   \n",
       "2                                     121694   \n",
       "3                                        230   \n",
       "4                                      15587   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2016  \\\n",
       "0                                        357   \n",
       "1                                       2747   \n",
       "2                                     121856   \n",
       "3                                        231   \n",
       "4                                      15516   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2017  \\\n",
       "0                                        363   \n",
       "1                                       2745   \n",
       "2                                     122210   \n",
       "3                                        226   \n",
       "4                                      15497   \n",
       "\n",
       "   Population Estimate (as of July 1) - 2018  \n",
       "0                                        367  \n",
       "1                                       2724  \n",
       "2                                     122999  \n",
       "3                                        227  \n",
       "4                                      15945  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Geography-Cities Column to a list\n",
    "\n",
    "cities = tx_cities['Geography']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Abbott city, Texas\n",
       "1    Abernathy city, Texas\n",
       "2      Abilene city, Texas\n",
       "3      Ackerly city, Texas\n",
       "4      Addison town, Texas\n",
       "Name: Geography, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean City name to remove city/town suffix and State\n",
    "\n",
    "tx_city_list = []\n",
    "for city in cities: \n",
    "    city = ' '.join(city.split()[:-2]).lower()\n",
    "    tx_city_list.append(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Houston Streets from Geographic.org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to scrape street names from Geographic.org\n",
    "# with state and city parameters\n",
    "\n",
    "\n",
    "def scrape_streets(state, city):\n",
    "    base = 'https://geographic.org/streetview/usa/'\n",
    "    suffix = '.html'\n",
    "    url = base + state +'/' + city + suffix\n",
    "    request = requests.get(base + state +'/' + city + suffix).text\n",
    "    soup = BeautifulSoup(request, 'lxml')\n",
    "    my_table = soup.find('span',{'class':'listspan'})\n",
    "    st_tags = my_table.findAll('a')\n",
    "\n",
    "    streets = []\n",
    "    for i in range(1,len(st_tags)):\n",
    "        streets.append(st_tags[i].string)\n",
    "    \n",
    "    return streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape streets for Houston, Texas\n",
    "\n",
    "streets = scrape_streets('tx', 'houston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12561"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12.5k streets from Google street view\n",
    "\n",
    "len(streets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case street names\n",
    "\n",
    "streets_low = [st.lower() for st in streets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adelle st', 'adina springs ln', 'adirondack dr', 'adler dr', 'adler lake dr']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets_low[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicate Street Names\n",
    "\n",
    "streets_low = list(set(streets_low))\n",
    "streets_low.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable for streets to drop\n",
    "# Street inside aiport causes some issues during lookup\n",
    "\n",
    "st_to_drop = ['a ave - william p. hobby airport (hou)']\n",
    "streets_low = [x for x in streets_low if x not in st_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Streets that have single name duplicate with \n",
    "# streets that have street suffix\n",
    "\n",
    "st_to_drop = []\n",
    "for i in range(len(streets_low)): \n",
    "    if len(streets_low[i].split()) < 2:\n",
    "        if streets_low[i].split()[0] == streets_low[i+1].split()[0]: \n",
    "            st_to_drop.append(streets_low[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Street Duplicates from above\n",
    "\n",
    "streets_low = [x for x in streets_low if x not in st_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many street names remaining\n",
    "\n",
    "len(streets_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Process Street Name List for Lookup \n",
    "# Reducing Street Name down to 1 or 2 words,without suffixes except for short words\n",
    "# Based on research, users only include suffix for short words\n",
    "\n",
    "def street_processing(street_list):\n",
    "\n",
    "    st_first  = [st.split(' ')[0] for st in street_list]  # create list of all first words\n",
    "\n",
    "    main_search = []                     # list to hold street_names used for lookup\n",
    "\n",
    "    for street in street_list: \n",
    "        first_word = street.split()[0]   # set first_word of street name to variable for test\n",
    "\n",
    "        if len(street.split()) < 2:      # if street name is only one word\n",
    "\n",
    "            if first_word[0].isdigit() == False:  # if first character is a letter\n",
    "\n",
    "                main_search.append(street)         # append the one word street name to main search list\n",
    "                #one_wd_st.append(street)           \n",
    "\n",
    "            else: \n",
    "                main_search.append(street +' '+ 'st')  # append one word digit name + 'st' to main search_list\n",
    "\n",
    "        elif len(street.split()) == 2:        # if street name is two words \n",
    "\n",
    "            second_word = street.split()[1]   # create second word variable for streets with at least 2 words\n",
    "\n",
    "\n",
    "            if len(first_word) < 6:          # if first word is less than 6 characters\n",
    "\n",
    "                #if first_word[0].isdigit() == False:   # if first character is char, this doesnt matter\n",
    "\n",
    "                main_search.append(first_word + ' ' + second_word)    # append first and second word to search\n",
    "\n",
    "            elif len(first_word) >= 6:         # if first word is at least 6 characters\n",
    "\n",
    "                if first_word[0].isdigit():   # first word starts with num\n",
    "\n",
    "                    main_search.append(first_word + ' ' + second_word) # append first and second word to search\n",
    "\n",
    "                else:                         # starts w char\n",
    "\n",
    "                    main_search.append(first_word)  # append only first word\n",
    "\n",
    "        elif len(street.split()) > 2:         # street name is more than two words\n",
    "\n",
    "            second_word = street.split()[1]   # create second word again for different if statement\n",
    "\n",
    "            main_search.append(first_word + ' ' + second_word)   # append first two words\n",
    "\n",
    "    return main_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execut Street Processing Function\n",
    "\n",
    "street_lookup = street_processing(streets_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Duplicates from newly cleaned street list\n",
    "\n",
    "street_lookup = list(set(street_lookup))\n",
    "street_lookup.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emergency Tweets for Address Extraction Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test tweets were manually pulled directly from Twitter, for known Harvey emergency related tweets on \n",
    "City of Houston Twitter account during the hurricane.  <br>\n",
    "<br>\n",
    "These Tweets are not in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_1 = ('My 83 y.o. Parents in imminent danger at 4922 Loch Lomond #Meyerland. Water knee deep inside home.'\n",
    "         ' Mom=heart condition. Dad=Alzheimer\\'s')\n",
    "\n",
    "twt_2 = ('We are not at inches, we are at 4-5 feet in this neighborhood. Wood Shadows II 11607 Lafferty Oaks')\n",
    "\n",
    "twt_3 = ('Plz help!! brother &family stuck in Dickson. 4901 38th street'\n",
    "         ' dickinson, tx 77539 his name is Rey (409) 999-0010')\n",
    "\n",
    "twt_4 = ('911 and coast guard ring busy. 4923 Braesvalley 77096.  4 adults, one disabled teen. on 2nd floor'\n",
    "         ' Elderly couple across street trapped.')\n",
    "\n",
    "twt_5 = ('We\\'re at the Redford Square Apartments 9406 Redford Street off 45 and Edgebrook'\n",
    "         ' we have a new born baby please help us the first floor Apart')\n",
    "\n",
    "twt_6 = ('412 Texas St. South Houston TX 77587')\n",
    "\n",
    "twt_7 = ('Apt 2105 at Meyer Forest Apts, she is handicapped and she cant get out, this is in Meyerland')\n",
    "\n",
    "#twt_8 = 'How \\'bout 12\"?  Is 12\" in a home a danger to an elderly person with limited mobility? '\\\n",
    "#         '2608 Martin Street, @PasadenaTX @PasadenaPD'\n",
    "    \n",
    "twt_8 = ('How \\'bout 12\"?  Is 12\" in a home a danger to an elderly person with limited mobility?'\n",
    "         ' 2608 Martin Street, PasadenaTX PasadenaPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tweets into list\n",
    "\n",
    "test_twts = [twt_1, twt_2,twt_3, twt_4, twt_5, twt_6, twt_7, twt_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case tweets\n",
    "\n",
    "twts_low = [twt.lower() for twt in test_twts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common words after numbers that are not addresses, will be used to filter tweets with\n",
    "# digits that are not address components\n",
    "\n",
    "num_excluders = ['feet', 'inches', 'people', 'adults']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing: Lookup Street Name and Extract Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lafferty\n",
      "lafferty oaks\n",
      "shadow\n"
     ]
    }
   ],
   "source": [
    "# Test Tweet 2\n",
    "\n",
    "matches = []\n",
    "count = 0\n",
    "for street in street_lookup: \n",
    "    if street in twt_2.lower(): \n",
    "        matches.append(street)\n",
    "        print(street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11607'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting Street Number\n",
    "\n",
    "twt_2_tok = twt_2.lower().split()\n",
    "\n",
    "match_idx = twt_2.lower().split().index(matches[0])\n",
    "\n",
    "if twt_2_tok[match_idx - 1].isdigit():\n",
    "    street_num = twt_2_tok[match_idx - 1]\n",
    "    \n",
    "street_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine above extractions\n",
    "\n",
    "min_address = []\n",
    "for match in matches: \n",
    "    if len(match.split()) > 1:\n",
    "        match_idx = twt_2.lower().split().index(match.split()[0])\n",
    "        if twt_2_tok[match_idx - 1].isdigit():\n",
    "            street_num = twt_2_tok[match_idx - 1]\n",
    "            min_address.append(street_num +' '+match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11607 lafferty oaks']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address Extraction method above requires additional development to extract the full address.  Because it was not fully complete, ultimately it was not used.  <br>\n",
    "<br>\n",
    "For this method to be effective, we will need to include street names for other cities and townships outside of Houston which are not on the current street lookup list.  Our dataset contains many tweets from Port Arthur and Dickinson, both outside of Houston. For tweets with those addresses, without those street lists we would overlook those address during the lookup and filter step.  <br>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Emergency (df_help) dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nb_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6624</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>9.0074e+17</td>\n",
       "      <td>Please don't forget about your pets during Tro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13617</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>9.01916e+17</td>\n",
       "      <td>Here's how you can help with #Tropical_Storm_H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14131</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>9.01931e+17</td>\n",
       "      <td>Come on #tropicalstorm #Harvey u need to go!!!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27074</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>9.0289e+17</td>\n",
       "      <td>Did you forget Harvey is a Tropical Storm and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33222</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Stay Safe #Texas Evacuate if you must &amp; don't ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33564</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Better hurry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33648</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>In your runs to get food and water, make sure ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33848</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>I?ve had stronger hurricanes at Pat O? Briens,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33984</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>#HurricaneHarvey pls come thru. I'm tryna slee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34346</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>#TRUMP will be there #HurricaneHarvey #TEXAS e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date           id  \\\n",
       "6624   2017-08-24   9.0074e+17   \n",
       "13617  2017-08-27  9.01916e+17   \n",
       "14131  2017-08-27  9.01931e+17   \n",
       "27074  2017-08-30   9.0289e+17   \n",
       "33222  2017-08-25     9.01e+17   \n",
       "33564  2017-08-25     9.01e+17   \n",
       "33648  2017-08-25     9.01e+17   \n",
       "33848  2017-08-25     9.01e+17   \n",
       "33984  2017-08-25     9.01e+17   \n",
       "34346  2017-08-25     9.01e+17   \n",
       "\n",
       "                                                   tweet  nb_label  \n",
       "6624   Please don't forget about your pets during Tro...         1  \n",
       "13617  Here's how you can help with #Tropical_Storm_H...         1  \n",
       "14131  Come on #tropicalstorm #Harvey u need to go!!!...         1  \n",
       "27074  Did you forget Harvey is a Tropical Storm and ...         1  \n",
       "33222  Stay Safe #Texas Evacuate if you must & don't ...         1  \n",
       "33564                                       Better hurry         1  \n",
       "33648  In your runs to get food and water, make sure ...         1  \n",
       "33848  I?ve had stronger hurricanes at Pat O? Briens,...         1  \n",
       "33984  #HurricaneHarvey pls come thru. I'm tryna slee...         1  \n",
       "34346  #TRUMP will be there #HurricaneHarvey #TEXAS e...         1  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_help.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 4)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_help.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Help Tweets for Potential Address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'has number' function to test if string has a digit\n",
    "\n",
    "def has_num(input_str):\n",
    "     return any(char.isdigit() for char in input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Check for Street Name match and presence of a digit in tweet\n",
    "# Create new columns with Binary Identifier 1 for match & list of street matches\n",
    "\n",
    "matches = []\n",
    "bin_match = []\n",
    "for twt in df_help['tweet']: \n",
    "    st_match = []\n",
    "    add_ct = 0 \n",
    "    bin_ct = 0\n",
    "    \n",
    "    for street in street_lookup:\n",
    "        if street in twt.lower():\n",
    "            if has_num(twt.lower()):\n",
    "                add_ct += 1\n",
    "                st_match.append(street)\n",
    "                bin_ct = 1\n",
    "    matches.append(st_match)\n",
    "    bin_match.append(bin_ct)\n",
    "df_help['st_matches'] = pd.Series(matches, index=df_help.index)\n",
    "df_help['bin_match'] = pd.Series(bin_match, index=df_help.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nb_label</th>\n",
       "      <th>st_matches</th>\n",
       "      <th>bin_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6624</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>9.0074e+17</td>\n",
       "      <td>Please don't forget about your pets during Tro...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13617</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>9.01916e+17</td>\n",
       "      <td>Here's how you can help with #Tropical_Storm_H...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey, tropical]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14131</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>9.01931e+17</td>\n",
       "      <td>Come on #tropicalstorm #Harvey u need to go!!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27074</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>9.0289e+17</td>\n",
       "      <td>Did you forget Harvey is a Tropical Storm and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33222</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Stay Safe #Texas Evacuate if you must &amp; don't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date           id  \\\n",
       "6624   2017-08-24   9.0074e+17   \n",
       "13617  2017-08-27  9.01916e+17   \n",
       "14131  2017-08-27  9.01931e+17   \n",
       "27074  2017-08-30   9.0289e+17   \n",
       "33222  2017-08-25     9.01e+17   \n",
       "\n",
       "                                                   tweet  nb_label  \\\n",
       "6624   Please don't forget about your pets during Tro...         1   \n",
       "13617  Here's how you can help with #Tropical_Storm_H...         1   \n",
       "14131  Come on #tropicalstorm #Harvey u need to go!!!...         1   \n",
       "27074  Did you forget Harvey is a Tropical Storm and ...         1   \n",
       "33222  Stay Safe #Texas Evacuate if you must & don't ...         1   \n",
       "\n",
       "               st_matches  bin_match  \n",
       "6624                   []          0  \n",
       "13617  [harvey, tropical]          1  \n",
       "14131                  []          0  \n",
       "27074                  []          0  \n",
       "33222                  []          0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_help.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    196\n",
       "Name: bin_match, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Street name + num matching counts\n",
    "\n",
    "df_help['bin_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe filtered for Address partial match\n",
    "\n",
    "df_add = df_help[df_help['bin_match']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 6)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Parsing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addresses Manually Inspected and Extracted\n",
    "Below addresses were pulled for testing and mapping in the following notebook prior to completion of above Parser function. These address were used in mapping for the demonstration of mapping functionality in the Presentation.  Some but not all of these address overlap with the identified addresses in the above filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [265179, 267654, 267451, 267422, 265192, 265161, 265146, 265145]\n",
    "address = ['9407 Cranleigh Ct. Houston 77096', '4724 Amalie St Houston','3226 Ave G',\n",
    "           '8015 Serenity Court Houston, TX', '5400 Bayou Dr. Dickson, TX', \n",
    "           'Big Bend Avenue, 39th St., Port Arthur','340 West 17th St. Port Arthur, TX 77640',\n",
    "          '3605 Jimmy Johnson Blvd Apt. 1002 Port Arthur TX 77642']\n",
    "lat = ['29.6784058','29.8551516' '29.465968099', '29.6948069', '29.4494273','29.9147006', '29.8748434', \n",
    "      '29.8748434', '29.945638']\n",
    "lng = ['-95.4633444','-95.323505099',  '-95.059360599', '-95.422081499', '-95.0609667', '-93.9485301',\n",
    "      '-93.9523373999999', '-93.952337399','-93.9755919999']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_1 = df.loc[265179, 'tweet']\n",
    "tweet_2 = df.loc[265145, 'tweet']\n",
    "tweet_3 = df.loc[267654, 'tweet']\n",
    "tweet_4 = df.loc[267451, 'tweet']\n",
    "tweet_5 = df.loc[267422, 'tweet']\n",
    "tweet_6 = df.loc[265161, 'tweet']\n",
    "tweet_7 = df.loc[265146, 'tweet']\n",
    "tweet_8 = df.loc[265145, 'tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Libpostal parser on raw Extracted Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@houstonpolice #harveyrescue #harveysos', 'house'),\n",
       " ('9407', 'house_number'),\n",
       " ('cranleigh ct.', 'road'),\n",
       " ('houston', 'city'),\n",
       " ('77096', 'postcode'),\n",
       " (\"please family of 5 need help. they're trapped on the roof #\", 'house'),\n",
       " ('houston', 'city')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_address(tweet_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@harveyrescue 3 adults and 4 children need help.', 'house'),\n",
       " ('3605', 'house_number'),\n",
       " ('jimmy johnson blvd', 'road'),\n",
       " ('apt. 1002', 'unit'),\n",
       " ('port arthur', 'city'),\n",
       " ('tx', 'state'),\n",
       " ('77642', 'postcode'),\n",
       " ('#harveysos', 'house')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_address(tweet_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"i've got a scared friend at 4724 amalie st. please send help @khou @houstonpolice @abc13houston @houstontx\",\n",
       "  'house')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_address(tweet_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my fil frank emmitte is trapped', 'house'),\n",
       " ('3226', 'house_number'),\n",
       " ('ave g', 'road'),\n",
       " (\"with 4-5' water. he is elderly cannot walk well. pls help retweet send info #hurricaneharvery\",\n",
       "  'house')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_address(tweet_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address Parser Functions to Manipulate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function uses libpostal address parser and reformats output into a dictionary\n",
    "\n",
    "def libpost_parser(tweet):\n",
    "    libpost = parse_address(tweet)\n",
    "    parsed_address = {}\n",
    "    for value, key in libpost: \n",
    "        parsed_address[key] = value\n",
    "\n",
    "    return parsed_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function on several tweets\n",
    "\n",
    "parsed_address = libpost_parser(twt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'house': 'we are not at inches we are at 4-5 feet in this neighborhood. wood shadows ii',\n",
       " 'house_number': '11607',\n",
       " 'road': 'lafferty oaks'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'house_number': '412',\n",
       " 'road': 'texas st.',\n",
       " 'city': 'south houston',\n",
       " 'state': 'tx',\n",
       " 'postcode': '77587'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libpost_parser(twt_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand libpostal parser function\n",
    "Process tweets in dataframe based on multiple conditionals about the validity of output from the libpostal parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full address parser function that asseses validity of the output from libpostal parser\n",
    "# based on city and street lookups, and returns a combined formatted address.\n",
    "\n",
    "def parser_full(tweet): \n",
    "    \n",
    "    tweet = tweet.replace('#', ' ').replace('@', ' ').replace('/', ' ')\n",
    "    libpost = parse_address(tweet)\n",
    "    parsed_address = {}\n",
    "    \n",
    "    for value, key in libpost: \n",
    "        parsed_address[key] = value\n",
    "    \n",
    "    st_num_bin = 0\n",
    "    street_bin = 0\n",
    "    city_bin = 0\n",
    "    state = 0\n",
    "    zip_bin = 0\n",
    "    \n",
    "    if 'house_number' in parsed_address:\n",
    "        if parsed_address['house_number'].isdigit() and (len(parsed_address['house_number']) < 6): \n",
    "            street_num = parsed_address['house_number']\n",
    "            st_num_bin = 1\n",
    "    else: \n",
    "        street_num = 'NA'\n",
    "    \n",
    "    if 'road' in parsed_address:\n",
    "        #if parsed_address['road'] in street_lookup:\n",
    "        street = parsed_address['road']\n",
    "        street_bin = 1  \n",
    "            \n",
    "        # Below section requires further testing to validate street    \n",
    "        #elif 'city' in parsed_address:\n",
    "            #if parsed_address['city'] in tx_city_list: #and parsed_address['city'] != 'houston':\n",
    "                #street = parsed_address['road']\n",
    "                #street_bin = 1 \n",
    "            #else: \n",
    "                #street = 'NA'\n",
    "        #else: \n",
    "            #street = 'NA'\n",
    "    else: \n",
    "        street = 'NA'\n",
    "    \n",
    "    if 'city' in parsed_address:\n",
    "        if parsed_address['city'] in tx_city_list:\n",
    "            city = parsed_address['city']\n",
    "            city_bin = 1\n",
    "    #else: \n",
    "        #city = 'houston'\n",
    "        #city_bin = 1\n",
    "\n",
    "    # Below block should be used when pulling data from multiple states     \n",
    "    if 'state' in parsed_address:\n",
    "        if len(parsed_address['state']) == 2:\n",
    "            state = parsed_address['state']\n",
    "            state_bin = 1;\n",
    "    else: \n",
    "        state = 'tx'\n",
    "        state_bin = 1\n",
    "    \n",
    "    if 'postcode' in parsed_address:\n",
    "        if parsed_address['postcode'].isdigit() and (len(parsed_address['postcode']) == 5):    \n",
    "            zipcode = parsed_address['postcode']\n",
    "            zip_bin = 1\n",
    "            \n",
    "    if st_num_bin == 0 and street_bin == 0: \n",
    "        formatted_addr = 'NA'\n",
    "        \n",
    "    if street_bin == 1:\n",
    "        if st_num_bin == 1: \n",
    "            if city_bin == 1: \n",
    "                if zip_bin == 1:\n",
    "                    formatted_addr = f'{street_num} {street}, {city}, {state} {zipcode}'\n",
    "                else: \n",
    "                    formatted_addr = f'{street_num} {street}, {city}, {state}'\n",
    "            elif zip_bin == 1: \n",
    "                formatted_addr = f'{street_num} {street}, {state} {zipcode}'\n",
    "            else: \n",
    "                formatted_addr = f'{street_num} {street}, {state}'\n",
    "        else:\n",
    "            if city_bin == 1: \n",
    "                if zip_bin == 1:\n",
    "                    formatted_addr = f'{street}, {city}, {state} {zipcode}'\n",
    "                else: \n",
    "                    formatted_addr = f'{street}, {city}, {state}'\n",
    "            elif zip_bin == 1: \n",
    "                formatted_addr = f'{street}, {state} {zipcode}'  \n",
    "            else: \n",
    "                formatted_addr = 'NA'\n",
    "    else: \n",
    "        formatted_addr = 'NA'\n",
    "    \n",
    "    \n",
    "    return formatted_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'412 texas st., south houston, tx 77587'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test parser function\n",
    "\n",
    "parser_full(twt_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'house_number': '412',\n",
       " 'road': 'texas st.',\n",
       " 'city': 'south houston',\n",
       " 'state': 'tx',\n",
       " 'postcode': '77587'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('forward 1 adult 8 year old w autism on top of car in garage', 'house'),\n",
       " ('2935', 'house_number'),\n",
       " ('40th st.', 'road'),\n",
       " ('port arthur', 'city'),\n",
       " ('tx', 'state'),\n",
       " ('77642', 'postcode'),\n",
       " ('sos help harvey harveysos', 'house')]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_address(df.loc[265164, 'tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2935 40th st., port arthur, tx 77642'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_full(df.loc[265164, 'tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Apply Address Parser to entire tweet column in dataframe creating new column\n",
    "\n",
    "df_add['formatted_addr'] = df_add['tweet'].apply(parser_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nb_label</th>\n",
       "      <th>st_matches</th>\n",
       "      <th>bin_match</th>\n",
       "      <th>formatted_addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39830</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>#Fema claims to be on the ground ready for #Hu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[e o, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>1 translation, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64158</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>AMERICA our fellow countrymen in Texas will ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>[country, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>4 once, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100630</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Volunteers: If U want 2 help with the aftermat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>2 u want, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108894</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Can't find the Bayport chapter on here. I went...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey, ina]</td>\n",
       "      <td>1</td>\n",
       "      <td>4 hurricaneharvey, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123008</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>RT this Thank you 4 making ppl aware of these ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[e o, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>4 rt this thank you, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265145</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/KaraBranch12/status/902802041478803456</td>\n",
       "      <td>@HarveyRescue 3 adults and 4 children need hel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, harvey, johnson]</td>\n",
       "      <td>1</td>\n",
       "      <td>3605 jimmy johnson blvd, port arthur, tx 77642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265146</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/tegan626/status/903020721378648068</td>\n",
       "      <td>My great grandfather needs a rescue at 340 Wes...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, h st, harvey, tierra]</td>\n",
       "      <td>1</td>\n",
       "      <td>west 17th st., tx 77640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265161</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/nyli/status/902834821449359360</td>\n",
       "      <td>#HarveySOS   In Port Arthur  on Big Bend Avenu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, avenue, big bend, e o, h st, harvey, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18 bend avenue off of 39th st. approx., tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265164</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/MomSkelton/status/902788660038295552</td>\n",
       "      <td>Forward\\n  ( 1 adult, 8 year old w/autism)\\nOn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, h st, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>2935 40th st., port arthur, tx 77642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265171</td>\n",
       "      <td>28 Aug 2017</td>\n",
       "      <td>/OneofTwin/status/902196100962148354</td>\n",
       "      <td>We need help in CE King Parkway Forest Subdivi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, harvey, parkway, sherry, vision]</td>\n",
       "      <td>1</td>\n",
       "      <td>8615 sherrywood drive, tx 77044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265179</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/MariaLauraQd/status/901941415592243202</td>\n",
       "      <td>@houstonpolice #HarveyRescue #HarveySOS 9407 C...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cranleigh, harvey, houston]</td>\n",
       "      <td>1</td>\n",
       "      <td>9407 cranleigh ct., houston, tx 77096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265192</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/RaeRoca/status/901836603211042822</td>\n",
       "      <td>A mom trapped in #HoustonFloods plz help:5400 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dickson, houston, patrick]</td>\n",
       "      <td>1</td>\n",
       "      <td>5400 bayou dr., houston, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265210</td>\n",
       "      <td>8 Sep 2017</td>\n",
       "      <td>/MelanieLawson13/status/906253040625360896</td>\n",
       "      <td>'I sang my first song in this church @Beyonce ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[church, harvey, houston, ina]</td>\n",
       "      <td>1</td>\n",
       "      <td>2 give to hurricaneharvey victims, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266374</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/piercethevic/status/903039675920551937</td>\n",
       "      <td>Donating some clothes to #HurricaneHarvey vict...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey, houston]</td>\n",
       "      <td>1</td>\n",
       "      <td>the address to donate is 2020 mangum rd., hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267422</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/MarianneM67/status/901930772885622787</td>\n",
       "      <td>PLEASE SEND HELP AND RETWEET, Kristi Hammerly...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hammerly, houston, tuck]</td>\n",
       "      <td>1</td>\n",
       "      <td>serenity court, houston, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267451</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/Thedockta/status/901839981026701315</td>\n",
       "      <td>My FIL Frank Emmitte is trapped 3226 Ave G wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>[frank]</td>\n",
       "      <td>1</td>\n",
       "      <td>3226 ave g, tx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date                                          id  \\\n",
       "39830    2017-08-25                                    9.01e+17   \n",
       "64158    2017-08-25                                    9.01e+17   \n",
       "100630   2017-08-26                                    9.01e+17   \n",
       "108894   2017-08-26                                    9.01e+17   \n",
       "123008   2017-08-26                                    9.01e+17   \n",
       "265145  30 Aug 2017     /KaraBranch12/status/902802041478803456   \n",
       "265146  30 Aug 2017         /tegan626/status/903020721378648068   \n",
       "265161  30 Aug 2017             /nyli/status/902834821449359360   \n",
       "265164  30 Aug 2017       /MomSkelton/status/902788660038295552   \n",
       "265171  28 Aug 2017        /OneofTwin/status/902196100962148354   \n",
       "265179  27 Aug 2017     /MariaLauraQd/status/901941415592243202   \n",
       "265192  27 Aug 2017          /RaeRoca/status/901836603211042822   \n",
       "265210   8 Sep 2017  /MelanieLawson13/status/906253040625360896   \n",
       "266374  30 Aug 2017     /piercethevic/status/903039675920551937   \n",
       "267422  27 Aug 2017      /MarianneM67/status/901930772885622787   \n",
       "267451  27 Aug 2017        /Thedockta/status/901839981026701315   \n",
       "\n",
       "                                                    tweet  nb_label  \\\n",
       "39830   #Fema claims to be on the ground ready for #Hu...         1   \n",
       "64158   AMERICA our fellow countrymen in Texas will ne...         1   \n",
       "100630  Volunteers: If U want 2 help with the aftermat...         1   \n",
       "108894  Can't find the Bayport chapter on here. I went...         1   \n",
       "123008  RT this Thank you 4 making ppl aware of these ...         1   \n",
       "265145  @HarveyRescue 3 adults and 4 children need hel...         1   \n",
       "265146  My great grandfather needs a rescue at 340 Wes...         1   \n",
       "265161  #HarveySOS   In Port Arthur  on Big Bend Avenu...         1   \n",
       "265164  Forward\\n  ( 1 adult, 8 year old w/autism)\\nOn...         1   \n",
       "265171  We need help in CE King Parkway Forest Subdivi...         1   \n",
       "265179  @houstonpolice #HarveyRescue #HarveySOS 9407 C...         1   \n",
       "265192  A mom trapped in #HoustonFloods plz help:5400 ...         1   \n",
       "265210  'I sang my first song in this church @Beyonce ...         1   \n",
       "266374  Donating some clothes to #HurricaneHarvey vict...         1   \n",
       "267422   PLEASE SEND HELP AND RETWEET, Kristi Hammerly...         1   \n",
       "267451  My FIL Frank Emmitte is trapped 3226 Ave G wit...         1   \n",
       "\n",
       "                                               st_matches  bin_match  \\\n",
       "39830                                       [e o, harvey]          1   \n",
       "64158                                   [country, harvey]          1   \n",
       "100630                                           [harvey]          1   \n",
       "108894                                      [harvey, ina]          1   \n",
       "123008                                      [e o, harvey]          1   \n",
       "265145                          [arthur, harvey, johnson]          1   \n",
       "265146                     [arthur, h st, harvey, tierra]          1   \n",
       "265161  [arthur, avenue, big bend, e o, h st, harvey, ...          1   \n",
       "265164                             [arthur, h st, harvey]          1   \n",
       "265171          [forest, harvey, parkway, sherry, vision]          1   \n",
       "265179                       [cranleigh, harvey, houston]          1   \n",
       "265192                        [dickson, houston, patrick]          1   \n",
       "265210                     [church, harvey, houston, ina]          1   \n",
       "266374                                  [harvey, houston]          1   \n",
       "267422                          [hammerly, houston, tuck]          1   \n",
       "267451                                            [frank]          1   \n",
       "\n",
       "                                           formatted_addr  \n",
       "39830                                   1 translation, tx  \n",
       "64158                                          4 once, tx  \n",
       "100630                                       2 u want, tx  \n",
       "108894                              4 hurricaneharvey, tx  \n",
       "123008                            4 rt this thank you, tx  \n",
       "265145     3605 jimmy johnson blvd, port arthur, tx 77642  \n",
       "265146                            west 17th st., tx 77640  \n",
       "265161         18 bend avenue off of 39th st. approx., tx  \n",
       "265164               2935 40th st., port arthur, tx 77642  \n",
       "265171                    8615 sherrywood drive, tx 77044  \n",
       "265179              9407 cranleigh ct., houston, tx 77096  \n",
       "265192                        5400 bayou dr., houston, tx  \n",
       "265210              2 give to hurricaneharvey victims, tx  \n",
       "266374  the address to donate is 2020 mangum rd., hous...  \n",
       "267422                        serenity court, houston, tx  \n",
       "267451                                     3226 ave g, tx  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Dataframe for non-'NA' values\n",
    "\n",
    "df_add[df_add['formatted_addr'] != 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 6 records are not addresses but escaped through the parser. These should be labeled as 'NA'.  Of the remaining 10 addresses, 8 appear to be useable, while 2 still include a a large amount extraneous text.  Parser needs further refinement.  We can also manually modify these address before sending them to the Geocoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geocodio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your personal API Key\n",
    "\n",
    "\n",
    "client = GeocodioClient('your_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address_components': {'number': '4901',\n",
       "  'predirectional': 'E',\n",
       "  'street': '38th',\n",
       "  'suffix': 'St',\n",
       "  'formatted_street': 'E 38th St',\n",
       "  'city': 'Dickinson',\n",
       "  'county': 'Galveston County',\n",
       "  'state': 'TX',\n",
       "  'zip': '77539',\n",
       "  'country': 'US'},\n",
       " 'formatted_address': '4901 E 38th St, Dickinson, TX 77539',\n",
       " 'location': {'lat': 29.466603, 'lng': -95.038147},\n",
       " 'accuracy': 0.9,\n",
       " 'accuracy_type': 'rooftop',\n",
       " 'source': 'Galveston'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Geocodio\n",
    "\n",
    "geo_loc2 = client.geocode('4901 38th Street,dickinson, tx')\n",
    "geo_loc2['results'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geocodio is nice that it gives us an accuracy score, which indicates a level of confidence in accuracy of the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Geocodio dictionary for Accuracy\n",
    "\n",
    "geo_loc2['results'][0]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 29.466603, 'lng': -95.038147}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Geocodio Dictionary for Lat/Long\n",
    "\n",
    "geo_loc2['results'][0]['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4901 E 38th St, Dickinson, TX 77539'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Geocodio Dictionary for Formatted Address\n",
    "\n",
    "geo_loc2['results'][0]['formatted_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'address_components': {'number': '4922',\n",
       "   'city': 'Loch Lomond',\n",
       "   'state': 'TX',\n",
       "   'country': 'US'},\n",
       "  'formatted_address': '4922, Loch Lomond, TX'},\n",
       " 'results': [],\n",
       " '_warnings': ['There is a newer API version available, please consider upgrading to v1.4. See changelog here: https://www.geocod.io/docs/#changelog']}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Geocodio without City or zip\n",
    "\n",
    "client.geocode('4922 Loch Lomond, tx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geocodio does not perform well without a city or zip code. So we likely will end up using Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how Geocodio will handle the 'NA' values\n",
    "\n",
    "# client.geocode('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geocodio's Error indicates that the city or zip is needed to geocode the address. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GoogleMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your personal API key\n",
    "\n",
    "gmaps = googlemaps.Client(key='your_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Google Geocoder without city or zip\n",
    "# Google does a much better job at identifying address without city or zip.\n",
    "\n",
    "goog_geo = gmaps.geocode('4922 loch lomond, tx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 29.6820753, 'lng': -95.4646344}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format Lat and Long\n",
    "\n",
    "goog_geo[0]['geometry']['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4922 Loch Lomond Dr, Houston, TX 77096, USA'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google Formatted Address\n",
    "\n",
    "goog_geo[0]['formatted_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google performs better on the above address without a city or zip. It can process the address with only street number, name and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address_components': [{'long_name': 'United States',\n",
       "    'short_name': 'US',\n",
       "    'types': ['country', 'political']}],\n",
       "  'formatted_address': 'United States',\n",
       "  'geometry': {'bounds': {'northeast': {'lat': 71.5388001, 'lng': -66.885417},\n",
       "    'southwest': {'lat': 18.7763, 'lng': 170.5957}},\n",
       "   'location': {'lat': 37.09024, 'lng': -95.712891},\n",
       "   'location_type': 'APPROXIMATE',\n",
       "   'viewport': {'northeast': {'lat': 49.38, 'lng': -66.94},\n",
       "    'southwest': {'lat': 25.82, 'lng': -124.39}}},\n",
       "  'place_id': 'ChIJCzYy5IS16lQRQrfeQ5K5Oxw',\n",
       "  'types': ['country', 'political']}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test how Google will handle 'NA' values\n",
    "\n",
    "gmaps.geocode('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Address through Google Geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean corrupt formatted address that Google Geocoder cannot process\n",
    "\n",
    "df_add.loc[239885, 'formatted_addr'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Non Null Address through Google Geocoder and Create new columns\n",
    "\n",
    "def goog_geocoder(df, col):\n",
    "\n",
    "    gmaps = googlemaps.Client(key='your_api_key')\n",
    "    \n",
    "    lat = []\n",
    "    long = []\n",
    "    goog_addr = []\n",
    "    \n",
    "    for row in df.index:\n",
    "    \n",
    "        if df.loc[row, col] != 'NA':\n",
    "            goog_geo = gmaps.geocode(df.loc[row,col])\n",
    "        \n",
    "            lat.append(goog_geo[0]['geometry']['location']['lat'])\n",
    "            long.append(goog_geo[0]['geometry']['location']['lng'])\n",
    "            goog_addr.append(goog_geo[0]['formatted_address'])\n",
    "    \n",
    "        else: \n",
    "            lat.append('NA')\n",
    "            long.append('NA')\n",
    "            goog_addr.append('NA')\n",
    "        \n",
    "    return lat, long, goog_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 7)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Google Geocoder to create latitude, longitude, and google address variables\n",
    "\n",
    "lat, lon, goog_addr = goog_geocoder(df_add, 'formatted_addr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Create new columns for the three variables\n",
    "\n",
    "df_add['goog_lat'] = pd.Series(lat, index=df_add.index)\n",
    "df_add['goog_lon'] = pd.Series(lon, index=df_add.index)\n",
    "df_add['goog_addr'] = pd.Series(goog_addr, index=df_add.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nb_label</th>\n",
       "      <th>st_matches</th>\n",
       "      <th>bin_match</th>\n",
       "      <th>formatted_addr</th>\n",
       "      <th>goog_lat</th>\n",
       "      <th>goog_lon</th>\n",
       "      <th>goog_addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39830</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>#Fema claims to be on the ground ready for #Hu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[e o, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>1 translation, tx</td>\n",
       "      <td>32.7579</td>\n",
       "      <td>-97.3246</td>\n",
       "      <td>Fort Worth, TX 76102, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64158</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>AMERICA our fellow countrymen in Texas will ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>[country, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>4 once, tx</td>\n",
       "      <td>29.9557</td>\n",
       "      <td>-95.5864</td>\n",
       "      <td>12525 Jones Rd, Houston, TX 77070, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100630</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Volunteers: If U want 2 help with the aftermat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>2 u want, tx</td>\n",
       "      <td>29.986</td>\n",
       "      <td>-95.1624</td>\n",
       "      <td>18455 W Lake Houston Pkwy #140, Humble, TX 773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108894</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>Can't find the Bayport chapter on here. I went...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey, ina]</td>\n",
       "      <td>1</td>\n",
       "      <td>4 hurricaneharvey, tx</td>\n",
       "      <td>31.9686</td>\n",
       "      <td>-99.9018</td>\n",
       "      <td>Texas, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123008</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>9.01e+17</td>\n",
       "      <td>RT this Thank you 4 making ppl aware of these ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[e o, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>4 rt this thank you, tx</td>\n",
       "      <td>31.9686</td>\n",
       "      <td>-99.9018</td>\n",
       "      <td>Texas, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265145</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/KaraBranch12/status/902802041478803456</td>\n",
       "      <td>@HarveyRescue 3 adults and 4 children need hel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, harvey, johnson]</td>\n",
       "      <td>1</td>\n",
       "      <td>3605 jimmy johnson blvd, port arthur, tx 77642</td>\n",
       "      <td>29.9456</td>\n",
       "      <td>-93.9756</td>\n",
       "      <td>3605 Jimmy Johnson Blvd, Port Arthur, TX 77642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265146</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/tegan626/status/903020721378648068</td>\n",
       "      <td>My great grandfather needs a rescue at 340 Wes...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, h st, harvey, tierra]</td>\n",
       "      <td>1</td>\n",
       "      <td>west 17th st., tx 77640</td>\n",
       "      <td>29.8732</td>\n",
       "      <td>-93.9542</td>\n",
       "      <td>W 17th St, Port Arthur, TX 77640, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265161</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/nyli/status/902834821449359360</td>\n",
       "      <td>#HarveySOS   In Port Arthur  on Big Bend Avenu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, avenue, big bend, e o, h st, harvey, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18 bend avenue off of 39th st. approx., tx</td>\n",
       "      <td>31.9686</td>\n",
       "      <td>-99.9018</td>\n",
       "      <td>Texas, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265164</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/MomSkelton/status/902788660038295552</td>\n",
       "      <td>Forward\\n  ( 1 adult, 8 year old w/autism)\\nOn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[arthur, h st, harvey]</td>\n",
       "      <td>1</td>\n",
       "      <td>2935 40th st., port arthur, tx 77642</td>\n",
       "      <td>29.9157</td>\n",
       "      <td>-93.9492</td>\n",
       "      <td>2935 40th St, Port Arthur, TX 77642, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265171</td>\n",
       "      <td>28 Aug 2017</td>\n",
       "      <td>/OneofTwin/status/902196100962148354</td>\n",
       "      <td>We need help in CE King Parkway Forest Subdivi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, harvey, parkway, sherry, vision]</td>\n",
       "      <td>1</td>\n",
       "      <td>8615 sherrywood drive, tx 77044</td>\n",
       "      <td>29.8507</td>\n",
       "      <td>-95.2063</td>\n",
       "      <td>8615 Sherrywood Dr, Houston, TX 77044, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265179</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/MariaLauraQd/status/901941415592243202</td>\n",
       "      <td>@houstonpolice #HarveyRescue #HarveySOS 9407 C...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cranleigh, harvey, houston]</td>\n",
       "      <td>1</td>\n",
       "      <td>9407 cranleigh ct., houston, tx 77096</td>\n",
       "      <td>29.6784</td>\n",
       "      <td>-95.4633</td>\n",
       "      <td>9407 Cranleigh Ct, Houston, TX 77096, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265192</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/RaeRoca/status/901836603211042822</td>\n",
       "      <td>A mom trapped in #HoustonFloods plz help:5400 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dickson, houston, patrick]</td>\n",
       "      <td>1</td>\n",
       "      <td>5400 bayou dr., houston, tx</td>\n",
       "      <td>29.6843</td>\n",
       "      <td>-95.2639</td>\n",
       "      <td>5400 N Bayou Dr, Houston, TX 77017, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265210</td>\n",
       "      <td>8 Sep 2017</td>\n",
       "      <td>/MelanieLawson13/status/906253040625360896</td>\n",
       "      <td>'I sang my first song in this church @Beyonce ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[church, harvey, houston, ina]</td>\n",
       "      <td>1</td>\n",
       "      <td>2 give to hurricaneharvey victims, tx</td>\n",
       "      <td>31.9686</td>\n",
       "      <td>-99.9018</td>\n",
       "      <td>Texas, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266374</td>\n",
       "      <td>30 Aug 2017</td>\n",
       "      <td>/piercethevic/status/903039675920551937</td>\n",
       "      <td>Donating some clothes to #HurricaneHarvey vict...</td>\n",
       "      <td>1</td>\n",
       "      <td>[harvey, houston]</td>\n",
       "      <td>1</td>\n",
       "      <td>the address to donate is 2020 mangum rd., hous...</td>\n",
       "      <td>29.8029</td>\n",
       "      <td>-95.4572</td>\n",
       "      <td>2020 Mangum Rd, Houston, TX 77092, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267422</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/MarianneM67/status/901930772885622787</td>\n",
       "      <td>PLEASE SEND HELP AND RETWEET, Kristi Hammerly...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hammerly, houston, tuck]</td>\n",
       "      <td>1</td>\n",
       "      <td>serenity court, houston, tx</td>\n",
       "      <td>29.6953</td>\n",
       "      <td>-95.4221</td>\n",
       "      <td>Serenity Ct, Houston, TX 77025, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267451</td>\n",
       "      <td>27 Aug 2017</td>\n",
       "      <td>/Thedockta/status/901839981026701315</td>\n",
       "      <td>My FIL Frank Emmitte is trapped 3226 Ave G wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>[frank]</td>\n",
       "      <td>1</td>\n",
       "      <td>3226 ave g, tx</td>\n",
       "      <td>29.466</td>\n",
       "      <td>-95.0594</td>\n",
       "      <td>3226 Avenue G, Dickinson, TX 77539, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date                                          id  \\\n",
       "39830    2017-08-25                                    9.01e+17   \n",
       "64158    2017-08-25                                    9.01e+17   \n",
       "100630   2017-08-26                                    9.01e+17   \n",
       "108894   2017-08-26                                    9.01e+17   \n",
       "123008   2017-08-26                                    9.01e+17   \n",
       "265145  30 Aug 2017     /KaraBranch12/status/902802041478803456   \n",
       "265146  30 Aug 2017         /tegan626/status/903020721378648068   \n",
       "265161  30 Aug 2017             /nyli/status/902834821449359360   \n",
       "265164  30 Aug 2017       /MomSkelton/status/902788660038295552   \n",
       "265171  28 Aug 2017        /OneofTwin/status/902196100962148354   \n",
       "265179  27 Aug 2017     /MariaLauraQd/status/901941415592243202   \n",
       "265192  27 Aug 2017          /RaeRoca/status/901836603211042822   \n",
       "265210   8 Sep 2017  /MelanieLawson13/status/906253040625360896   \n",
       "266374  30 Aug 2017     /piercethevic/status/903039675920551937   \n",
       "267422  27 Aug 2017      /MarianneM67/status/901930772885622787   \n",
       "267451  27 Aug 2017        /Thedockta/status/901839981026701315   \n",
       "\n",
       "                                                    tweet  nb_label  \\\n",
       "39830   #Fema claims to be on the ground ready for #Hu...         1   \n",
       "64158   AMERICA our fellow countrymen in Texas will ne...         1   \n",
       "100630  Volunteers: If U want 2 help with the aftermat...         1   \n",
       "108894  Can't find the Bayport chapter on here. I went...         1   \n",
       "123008  RT this Thank you 4 making ppl aware of these ...         1   \n",
       "265145  @HarveyRescue 3 adults and 4 children need hel...         1   \n",
       "265146  My great grandfather needs a rescue at 340 Wes...         1   \n",
       "265161  #HarveySOS   In Port Arthur  on Big Bend Avenu...         1   \n",
       "265164  Forward\\n  ( 1 adult, 8 year old w/autism)\\nOn...         1   \n",
       "265171  We need help in CE King Parkway Forest Subdivi...         1   \n",
       "265179  @houstonpolice #HarveyRescue #HarveySOS 9407 C...         1   \n",
       "265192  A mom trapped in #HoustonFloods plz help:5400 ...         1   \n",
       "265210  'I sang my first song in this church @Beyonce ...         1   \n",
       "266374  Donating some clothes to #HurricaneHarvey vict...         1   \n",
       "267422   PLEASE SEND HELP AND RETWEET, Kristi Hammerly...         1   \n",
       "267451  My FIL Frank Emmitte is trapped 3226 Ave G wit...         1   \n",
       "\n",
       "                                               st_matches  bin_match  \\\n",
       "39830                                       [e o, harvey]          1   \n",
       "64158                                   [country, harvey]          1   \n",
       "100630                                           [harvey]          1   \n",
       "108894                                      [harvey, ina]          1   \n",
       "123008                                      [e o, harvey]          1   \n",
       "265145                          [arthur, harvey, johnson]          1   \n",
       "265146                     [arthur, h st, harvey, tierra]          1   \n",
       "265161  [arthur, avenue, big bend, e o, h st, harvey, ...          1   \n",
       "265164                             [arthur, h st, harvey]          1   \n",
       "265171          [forest, harvey, parkway, sherry, vision]          1   \n",
       "265179                       [cranleigh, harvey, houston]          1   \n",
       "265192                        [dickson, houston, patrick]          1   \n",
       "265210                     [church, harvey, houston, ina]          1   \n",
       "266374                                  [harvey, houston]          1   \n",
       "267422                          [hammerly, houston, tuck]          1   \n",
       "267451                                            [frank]          1   \n",
       "\n",
       "                                           formatted_addr goog_lat goog_lon  \\\n",
       "39830                                   1 translation, tx  32.7579 -97.3246   \n",
       "64158                                          4 once, tx  29.9557 -95.5864   \n",
       "100630                                       2 u want, tx   29.986 -95.1624   \n",
       "108894                              4 hurricaneharvey, tx  31.9686 -99.9018   \n",
       "123008                            4 rt this thank you, tx  31.9686 -99.9018   \n",
       "265145     3605 jimmy johnson blvd, port arthur, tx 77642  29.9456 -93.9756   \n",
       "265146                            west 17th st., tx 77640  29.8732 -93.9542   \n",
       "265161         18 bend avenue off of 39th st. approx., tx  31.9686 -99.9018   \n",
       "265164               2935 40th st., port arthur, tx 77642  29.9157 -93.9492   \n",
       "265171                    8615 sherrywood drive, tx 77044  29.8507 -95.2063   \n",
       "265179              9407 cranleigh ct., houston, tx 77096  29.6784 -95.4633   \n",
       "265192                        5400 bayou dr., houston, tx  29.6843 -95.2639   \n",
       "265210              2 give to hurricaneharvey victims, tx  31.9686 -99.9018   \n",
       "266374  the address to donate is 2020 mangum rd., hous...  29.8029 -95.4572   \n",
       "267422                        serenity court, houston, tx  29.6953 -95.4221   \n",
       "267451                                     3226 ave g, tx   29.466 -95.0594   \n",
       "\n",
       "                                                goog_addr  \n",
       "39830                           Fort Worth, TX 76102, USA  \n",
       "64158              12525 Jones Rd, Houston, TX 77070, USA  \n",
       "100630  18455 W Lake Houston Pkwy #140, Humble, TX 773...  \n",
       "108894                                         Texas, USA  \n",
       "123008                                         Texas, USA  \n",
       "265145  3605 Jimmy Johnson Blvd, Port Arthur, TX 77642...  \n",
       "265146              W 17th St, Port Arthur, TX 77640, USA  \n",
       "265161                                         Texas, USA  \n",
       "265164           2935 40th St, Port Arthur, TX 77642, USA  \n",
       "265171         8615 Sherrywood Dr, Houston, TX 77044, USA  \n",
       "265179          9407 Cranleigh Ct, Houston, TX 77096, USA  \n",
       "265192            5400 N Bayou Dr, Houston, TX 77017, USA  \n",
       "265210                                         Texas, USA  \n",
       "266374             2020 Mangum Rd, Houston, TX 77092, USA  \n",
       "267422                Serenity Ct, Houston, TX 77025, USA  \n",
       "267451            3226 Avenue G, Dickinson, TX 77539, USA  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Dataframe for non-null Google generated latitudes\n",
    "\n",
    "df_add[df_add['goog_lat'] != 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google generated an address with coordinates for everything we throw at it, even though we know that at least four of the addresses are not actual addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Dataframe and Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = df_add[df_add['goog_lat'] != 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_drop = [39830, 64158, 100630, 108894, 123008, 265161, 265210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Garrett/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_add.drop(idx_to_drop, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['date', 'id', 'st_matches', 'formatted_addr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add.drop(columns = cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>nb_label</th>\n",
       "      <th>bin_match</th>\n",
       "      <th>goog_lat</th>\n",
       "      <th>goog_lon</th>\n",
       "      <th>goog_addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>265145</td>\n",
       "      <td>@HarveyRescue 3 adults and 4 children need hel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.9456</td>\n",
       "      <td>-93.9756</td>\n",
       "      <td>3605 Jimmy Johnson Blvd, Port Arthur, TX 77642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265146</td>\n",
       "      <td>My great grandfather needs a rescue at 340 Wes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.8732</td>\n",
       "      <td>-93.9542</td>\n",
       "      <td>W 17th St, Port Arthur, TX 77640, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265164</td>\n",
       "      <td>Forward\\n  ( 1 adult, 8 year old w/autism)\\nOn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.9157</td>\n",
       "      <td>-93.9492</td>\n",
       "      <td>2935 40th St, Port Arthur, TX 77642, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265171</td>\n",
       "      <td>We need help in CE King Parkway Forest Subdivi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.8507</td>\n",
       "      <td>-95.2063</td>\n",
       "      <td>8615 Sherrywood Dr, Houston, TX 77044, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265179</td>\n",
       "      <td>@houstonpolice #HarveyRescue #HarveySOS 9407 C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.6784</td>\n",
       "      <td>-95.4633</td>\n",
       "      <td>9407 Cranleigh Ct, Houston, TX 77096, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265192</td>\n",
       "      <td>A mom trapped in #HoustonFloods plz help:5400 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.6843</td>\n",
       "      <td>-95.2639</td>\n",
       "      <td>5400 N Bayou Dr, Houston, TX 77017, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266374</td>\n",
       "      <td>Donating some clothes to #HurricaneHarvey vict...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.8029</td>\n",
       "      <td>-95.4572</td>\n",
       "      <td>2020 Mangum Rd, Houston, TX 77092, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267422</td>\n",
       "      <td>PLEASE SEND HELP AND RETWEET, Kristi Hammerly...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.6953</td>\n",
       "      <td>-95.4221</td>\n",
       "      <td>Serenity Ct, Houston, TX 77025, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267451</td>\n",
       "      <td>My FIL Frank Emmitte is trapped 3226 Ave G wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.466</td>\n",
       "      <td>-95.0594</td>\n",
       "      <td>3226 Avenue G, Dickinson, TX 77539, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  nb_label  \\\n",
       "265145  @HarveyRescue 3 adults and 4 children need hel...         1   \n",
       "265146  My great grandfather needs a rescue at 340 Wes...         1   \n",
       "265164  Forward\\n  ( 1 adult, 8 year old w/autism)\\nOn...         1   \n",
       "265171  We need help in CE King Parkway Forest Subdivi...         1   \n",
       "265179  @houstonpolice #HarveyRescue #HarveySOS 9407 C...         1   \n",
       "265192  A mom trapped in #HoustonFloods plz help:5400 ...         1   \n",
       "266374  Donating some clothes to #HurricaneHarvey vict...         1   \n",
       "267422   PLEASE SEND HELP AND RETWEET, Kristi Hammerly...         1   \n",
       "267451  My FIL Frank Emmitte is trapped 3226 Ave G wit...         1   \n",
       "\n",
       "        bin_match goog_lat goog_lon  \\\n",
       "265145          1  29.9456 -93.9756   \n",
       "265146          1  29.8732 -93.9542   \n",
       "265164          1  29.9157 -93.9492   \n",
       "265171          1  29.8507 -95.2063   \n",
       "265179          1  29.6784 -95.4633   \n",
       "265192          1  29.6843 -95.2639   \n",
       "266374          1  29.8029 -95.4572   \n",
       "267422          1  29.6953 -95.4221   \n",
       "267451          1   29.466 -95.0594   \n",
       "\n",
       "                                                goog_addr  \n",
       "265145  3605 Jimmy Johnson Blvd, Port Arthur, TX 77642...  \n",
       "265146              W 17th St, Port Arthur, TX 77640, USA  \n",
       "265164           2935 40th St, Port Arthur, TX 77642, USA  \n",
       "265171         8615 Sherrywood Dr, Houston, TX 77044, USA  \n",
       "265179          9407 Cranleigh Ct, Houston, TX 77096, USA  \n",
       "265192            5400 N Bayou Dr, Houston, TX 77017, USA  \n",
       "266374             2020 Mangum Rd, Houston, TX 77092, USA  \n",
       "267422                Serenity Ct, Houston, TX 77025, USA  \n",
       "267451            3226 Avenue G, Dickinson, TX 77539, USA  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Dataframe to export\n",
    "\n",
    "df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "\n",
    "df_add.to_csv('./data/geo_coords.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
